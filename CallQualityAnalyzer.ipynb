{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPA8pmdojpmVfAAZ/E/vToY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Athaxv/VoiceAI/blob/main/CallQualityAnalyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Call Quality Analyzer\n",
        "\n",
        "**By:** Atharv Gaur\n",
        "**Date:** September 13, 2025\n",
        "\n",
        "This notebook analyzes a sales call recording to extract key quality metrics, sentiment, and actionable insights.\n"
      ],
      "metadata": {
        "id": "PMl4P8zsZg59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Installing necessary packages...\")\n",
        "!pip install -q pytubefix ffmpeg-python assemblyai transformers torch\n",
        "\n",
        "print(\"\\nInstallations complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2sBqwUrZkpN",
        "outputId": "c32f9ddc-8d7c-42b6-b54e-c52bd196c00a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing necessary packages...\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m768.9/768.9 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\n",
            "Installations complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 2: Configure API Key\n",
        "import assemblyai as aai\n",
        "\n",
        "# IMPORTANT: Replace \"YOUR_API_KEY_HERE\" with your actual AssemblyAI API key.\n",
        "aai.settings.api_key = \"2eea341f4de24170aa7b6a590d76c1c7\"\n",
        "\n",
        "print(\"AssemblyAI API key configured.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xzr2M_AFbjeG",
        "outputId": "a6ec7f6b-9c65-460f-98a5-3fa86935df07"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AssemblyAI API key configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 3: Extract Audio from YouTube\n",
        "from pytubefix import YouTube\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# URL of the YouTube video to be analyzed\n",
        "YOUTUBE_URL = \"https://www.youtube.com/shorts/AwK-nzl1jHM\"\n",
        "AUDIO_FILE_MP4 = \"call_audio.mp4\"\n",
        "AUDIO_FILE_WAV = \"call_audio.wav\"\n",
        "\n",
        "print(f\"Downloading audio from: {YOUTUBE_URL}\")\n",
        "\n",
        "# Download the best audio stream using pytube\n",
        "yt = YouTube(YOUTUBE_URL)\n",
        "audio_stream = yt.streams.filter(only_audio=True).first()\n",
        "audio_stream.download(filename=AUDIO_FILE_MP4)\n",
        "\n",
        "print(f\"Successfully downloaded audio to {AUDIO_FILE_MP4}\")\n",
        "\n",
        "# Convert the downloaded mp4 file to a WAV file using ffmpeg.\n",
        "# WAV is a standard format for many speech recognition models.\n",
        "# We also convert it to mono channel and set a sample rate of 16kHz.\n",
        "print(\"Converting MP4 to WAV...\")\n",
        "subprocess.run([\n",
        "    'ffmpeg',\n",
        "    '-i', AUDIO_FILE_MP4,\n",
        "    '-ac', '1',          # Mono channel\n",
        "    '-ar', '16000',      # 16kHz sample rate\n",
        "    AUDIO_FILE_WAV,\n",
        "    '-y'                 # Overwrite output file if it exists\n",
        "], check=True)\n",
        "\n",
        "\n",
        "print(f\"Successfully converted audio to {AUDIO_FILE_WAV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_1HLYhSbtKW",
        "outputId": "61d22851-8c25-4f78-ff8f-add581426d6b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading audio from: https://www.youtube.com/shorts/AwK-nzl1jHM\n",
            "Successfully downloaded audio to call_audio.mp4\n",
            "Converting MP4 to WAV...\n",
            "Successfully converted audio to call_audio.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 4: Transcribe the Audio and Identify Speakers\n",
        "import time\n",
        "\n",
        "print(\"Starting transcription process... This may take a moment.\")\n",
        "start_time = time.time()\n",
        "\n",
        "# Configure the transcription request with speaker identification (diarization) and sentiment analysis\n",
        "config = aai.TranscriptionConfig(\n",
        "    speaker_labels=True,\n",
        "    sentiment_analysis=True,\n",
        "    summarization=True,  # <-- THIS MUST BE TRUE\n",
        "    summary_model=aai.SummarizationModel.informative, # You can choose different models\n",
        "    summary_type=aai.SummarizationType.bullets      # 'bullets', 'paragraph', etc.\n",
        ")\n",
        "\n",
        "# Create a transcriber object\n",
        "transcriber = aai.Transcriber()\n",
        "\n",
        "# Start the transcription\n",
        "transcript = transcriber.transcribe(AUDIO_FILE_WAV, config)\n",
        "\n",
        "# Check for transcription errors\n",
        "if isinstance(transcript, aai.RealtimeTranscript):\n",
        "    if transcript.error:\n",
        "        print(f\"An error occurred: {transcript.error}\")\n",
        "else:\n",
        "    processing_time = time.time() - start_time\n",
        "    print(f\"Transcription complete in {processing_time:.2f} seconds.\")\n",
        "    # The transcript object now contains the full text, timestamps, and speaker labels."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riu60Ljkbygp",
        "outputId": "6113b43e-dba5-41cf-f5fb-39abc9a81d33"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting transcription process... This may take a moment.\n",
            "Transcription complete in 16.41 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 5: Final Report\n",
        "from collections import defaultdict\n",
        "import operator\n",
        "\n",
        "print(\"--- Call Quality Analysis Report ---\\n\")\n",
        "\n",
        "# Initialize variables to avoid errors if transcript is empty\n",
        "speaker_talk_time = defaultdict(float)\n",
        "speaker_question_count = defaultdict(int)\n",
        "sales_rep_speaker = \"Unknown\"\n",
        "talk_time_ratio = {}\n",
        "total_question_count = 0\n",
        "longest_monologue_duration = 0\n",
        "longest_monologue_speaker = \"Unknown\"\n",
        "overall_sentiment_label = \"NEUTRAL\"\n",
        "actionable_insight = \"Not available.\"\n",
        "\n",
        "if transcript.utterances:\n",
        "    # --- Enhanced Role Identification (Bonus) ---\n",
        "    first_speaker_label = transcript.utterances[0].speaker\n",
        "\n",
        "    for utterance in transcript.utterances:\n",
        "        speaker = utterance.speaker\n",
        "        duration = utterance.end - utterance.start\n",
        "        speaker_talk_time[speaker] += duration\n",
        "        speaker_question_count[speaker] += utterance.text.count('?')\n",
        "\n",
        "    heuristic_scores = defaultdict(float)\n",
        "    for speaker, talk_time in speaker_talk_time.items():\n",
        "        score = talk_time\n",
        "        score += speaker_question_count[speaker] * 5000\n",
        "        if speaker == first_speaker_label:\n",
        "            score += 10000\n",
        "        heuristic_scores[speaker] = score\n",
        "\n",
        "    if heuristic_scores:\n",
        "        sales_rep_speaker = max(heuristic_scores.items(), key=operator.itemgetter(1))[0]\n",
        "\n",
        "    # --- 1. Calculate and Display Talk-Time Ratio (FIXED) ---\n",
        "    # The total duration is on the main transcript object\n",
        "    total_duration_ms = transcript.audio_duration if transcript.audio_duration else 1\n",
        "    talk_time_ratio = {speaker: (duration / total_duration_ms) * 100 for speaker, duration in speaker_talk_time.items()}\n",
        "\n",
        "    # --- 2. Count Number of Questions ---\n",
        "    total_question_count = sum(speaker_question_count.values())\n",
        "\n",
        "    # --- 3. Find Longest Monologue ---\n",
        "    for utterance in transcript.utterances:\n",
        "        duration = (utterance.end - utterance.start) / 1000\n",
        "        if duration > longest_monologue_duration:\n",
        "            longest_monologue_duration = duration\n",
        "            longest_monologue_speaker = utterance.speaker\n",
        "\n",
        "# --- 4. Analyze Call Sentiment (FIXED) ---\n",
        "# The 'sentiment' attribute is a simple string, not an enum.\n",
        "if transcript.sentiment_analysis:\n",
        "    sentiments = [result.sentiment for result in transcript.sentiment_analysis]\n",
        "\n",
        "    # Compare against strings \"POSITIVE\", \"NEGATIVE\", \"NEUTRAL\"\n",
        "    positive_count = sentiments.count(\"POSITIVE\")\n",
        "    negative_count = sentiments.count(\"NEGATIVE\")\n",
        "    neutral_count = sentiments.count(\"NEUTRAL\")\n",
        "\n",
        "    if positive_count > negative_count and positive_count > neutral_count:\n",
        "        overall_sentiment_label = \"POSITIVE\"\n",
        "    elif negative_count > positive_count and negative_count > neutral_count:\n",
        "        overall_sentiment_label = \"NEGATIVE\"\n",
        "\n",
        "# --- 5. Generate Actionable Insight ---\n",
        "if transcript.summary:\n",
        "    actionable_insight = transcript.summary\n",
        "\n",
        "\n",
        "# --- Display Final Report ---\n",
        "print(\"1. Talk-Time Ratio:\")\n",
        "if talk_time_ratio:\n",
        "    for speaker, ratio in talk_time_ratio.items():\n",
        "        speaker_role = \"Sales Rep\" if speaker == sales_rep_speaker else \"Customer\"\n",
        "        print(f\"   - Speaker {speaker} ({speaker_role}): {ratio:.2f}%\")\n",
        "else:\n",
        "    print(\"   - No speaker data available.\")\n",
        "\n",
        "print(f\"\\n2. Number of Questions Asked: {total_question_count}\")\n",
        "print(f\"\\n3. Longest Monologue: {longest_monologue_duration:.2f} seconds (by Speaker {longest_monologue_speaker})\")\n",
        "print(f\"\\n4. Overall Call Sentiment: {overall_sentiment_label}\")\n",
        "print(f\"\\n5. Actionable Insight:\\n{actionable_insight}\")\n",
        "\n",
        "print(\"\\n--- End of Report ---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uWSDGtnb3Cp",
        "outputId": "18f853ff-1da8-48bb-e61c-fcd85a18f0b8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Call Quality Analysis Report ---\n",
            "\n",
            "1. Talk-Time Ratio:\n",
            "   - Speaker B (Customer): 30343.10%\n",
            "   - Speaker A (Sales Rep): 61484.48%\n",
            "\n",
            "2. Number of Questions Asked: 4\n",
            "\n",
            "3. Longest Monologue: 15.46 seconds (by Speaker A)\n",
            "\n",
            "4. Overall Call Sentiment: NEUTRAL\n",
            "\n",
            "5. Actionable Insight:\n",
            "- We are a social media production company. It was a quick call to see if you guys are looking for help with social media. Currently we're not looking for anyone, but thank you for the call.\n",
            "- Have you worked in education? Yes, we've worked with. three companies already. The task with education is a different sector. If you could send me your company profile, I could have a look at it. We can probably hop on a quick call together and hopefully work this out.\n",
            "\n",
            "--- End of Report ---\n"
          ]
        }
      ]
    }
  ]
}